x-airflow-env: &airflow-env
  AIRFLOW__CORE__EXECUTOR: ${AIRFLOW__CORE__EXECUTOR:-LocalExecutor}
  AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://${POSTGRES_USER:-airflow}:${POSTGRES_PASSWORD:-airflow}@postgres:5432/${POSTGRES_DB:-airflow}
  # AIRFLOW__WEBSERVER__RBAC: "True"
  AIRFLOW__CORE__LOAD_EXAMPLES: ${AIRFLOW__CORE__LOAD_EXAMPLES:-False}
  # Fernet key sourced from Hydra configuration
  AIRFLOW__CORE__FERNET_KEY: ${AIRFLOW__CORE__FERNET_KEY}
  # Authentication credentials for Airflow admin user
  _AIRFLOW_WWW_USER_USERNAME: ${_AIRFLOW_WWW_USER_USERNAME:-admin}
  _AIRFLOW_WWW_USER_PASSWORD: ${_AIRFLOW_WWW_USER_PASSWORD:-admin}

# Common volume configurations for caching optimization
x-airflow-volumes: &airflow-volumes
  - ../dags:/opt/airflow/dags:cached  # Use cached mount for better performance
  - ../airflow/plugins:/opt/airflow/plugins:cached
  - airflow_logs:/opt/airflow/logs
  - pip_cache:/home/airflow/.cache/pip  # Cache pip downloads
  - uv_cache:/home/airflow/.cache/uv    # Cache UV downloads

services:
  postgres:
    image: docker.io/library/postgres:${POSTGRES_VERSION:-15}
    env_file: [./postgres.env]
    volumes:
      - pg_data:/var/lib/postgresql/data
    # Publish to a free host port by default; override via PGHOSTPORT in .env if desired
    ports:
      - target: 5432
        published: ${PGHOSTPORT:-0}
        protocol: tcp
        mode: host
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U $$POSTGRES_USER"]
      interval: 10s
      timeout: 5s
      retries: 5

  airflow-init:
    build:
      context: ..
      dockerfile: Dockerfile.airflow
      target: development
      args:
        AIRFLOW_VERSION: ${AIRFLOW_VERSION:-2.9.3}
        PYTHON_VERSION: ${PYTHON_VERSION:-3.12}
    image: {{cookiecutter.repo_slug}}-airflow-dev
    env_file: [./airflow.env]
    environment: *airflow-env
    user: "50000:0"
    volumes: *airflow-volumes
    command: [
      "bash", "-c",
      "airflow db upgrade && airflow users create --username $$_AIRFLOW_WWW_USER_USERNAME --password $$_AIRFLOW_WWW_USER_PASSWORD --firstname Admin --lastname User --role Admin --email admin@example.com 2>/dev/null || echo 'Admin user already exists'"
    ]
    restart: "no"
    depends_on:
      postgres:
        condition: service_healthy

  airflow-scheduler:
    build:
      context: ..
      dockerfile: Dockerfile.airflow
      target: development
      args:
        AIRFLOW_VERSION: ${AIRFLOW_VERSION:-2.9.3}
        PYTHON_VERSION: ${PYTHON_VERSION:-3.12}
    image: {{cookiecutter.repo_slug}}-airflow-dev
    env_file: [./airflow.env]
    environment: *airflow-env
    user: "50000:0"
    command: ["airflow", "scheduler"]
    volumes: *airflow-volumes
    depends_on:
      airflow-init:
        condition: service_completed_successfully

  airflow-webserver:
    build:
      context: ..
      dockerfile: Dockerfile.airflow
      target: development
      args:
        AIRFLOW_VERSION: ${AIRFLOW_VERSION:-2.9.3}
        PYTHON_VERSION: ${PYTHON_VERSION:-3.12}
    image: {{cookiecutter.repo_slug}}-airflow-dev
    env_file: [./airflow.env]
    environment: *airflow-env
    user: "50000:0"
    command: ["airflow", "webserver"]
    ports:
      - "8080:8080"
    volumes: *airflow-volumes
    depends_on:
      airflow-init:
        condition: service_completed_successfully

  # DevContainer service (what VS Code opens into)
  devcontainer:
    image: mcr.microsoft.com/devcontainers/python:{{cookiecutter.python_version}}
    command: sleep infinity
    # Ensure the service runs as the same non-root user VS Code connects as
    user: "1000:1000"  # Use consistent UID/GID for vscode user
    init: true
    volumes:
      - ..:/workspaces/{{cookiecutter.repo_slug}}
    working_dir: /workspaces/{{cookiecutter.repo_slug}}
    depends_on:
      - airflow-webserver
      - airflow-scheduler
      - postgres

volumes:
  pg_data:
  airflow_logs:    # Persistent logs for debugging  
  pip_cache:       # Cache pip downloads for faster builds
  uv_cache:        # Cache UV downloads for faster dependency resolution